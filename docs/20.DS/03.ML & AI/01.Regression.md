---
title: Regression
date: 2022-09-20 14:59:33
permalink: /pages/6fc208/
categories:
  - DS
  - ML & AI
tags:
  - 
author: 
  name: Jennifer
  link: https://github.com/Li-Jennifer
---

## Regression(回归)
## 1. Linear regression（线性回归）
### 1.1Variables
Olympic : X

Winning time: Y
### 1.2Modle
t = f(x)
### 1.3Data (training data)
- N attribute-response pairs, (Xn, tn)
- e.g. (1896,12s), (1900, 11s), . .., (2008, 9.69s)
- X1 = 1896, t1 = 12, etc
### 1.4 Linear Model
t = f (x) = w0 + w1x = f(x;,w0,w1)
#### a. W_0, W_1 (best)
#### b.Loss function
![](../../img/ml_loss.png)
#### c. Squared Loss
![](../../img/ml_squared.png)
#### e.Average Squared loss
![](../../img/ml_average.png)
#### f. argmin L
![](../../img/ml_argmin.png)
#### g.Gradient Descent(梯度下降)
![](../../img/ml_gradient.png)
![](../../img/ml_gradient_descent.png)

#### h.supplementary
![](../../img/ml_supplementary.png)
## 2.Polynomial regression(多项式回归)
### 2.1 Polynomial
![](../../img/ml_ployn.png)
### 2.2 Vector form (still a linear regression)
![](../../img/ml_ploynomial.png)
### 2.3 Minimizing the loss
![](../../img/ml_minimizing.png)
### 2.4 General Linear Regression
![](../../img/ml_general_linear.png)
### 2.5 Generalization and over-fitting   泛化和过度学习
Nosie :噪音
### 2.6 Cross-validation(CV) 交叉验证
repeat to make results more accurate
1. 5-fold CV
2. 10-fold CV 
3. Leave-one-out CV (LOOCV) 留一法
![](../../img/ml_loocv.png)

### 2.5 Common function
![](../../img/ml_basic_function.png)
![](../../img/ml_function_graph.png)
##  3.Bayesian linear regression (贝叶斯线性回归)
### 3.1 Bayes rule
![](../../img/ml_bayes.png)
### 3.2 compute
![](../../img/ml_bayes_compute.png)
### 3.3 likelihood, posterior, and data (可能性，后验和数据)
![](../../img/ml_bayes_likelihood.png)