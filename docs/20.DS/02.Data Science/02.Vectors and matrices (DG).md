---
title: Vectors and matrices (DG)
date: 2022-09-20 07:11:03
permalink: /pages/a9ccf5/
categories:
  - DS
  - Data Science
tags:
  - 
author: 
  name: Jennifer
  link: https://github.com/Li-Jennifer
---
1. 什么是向量，什么是向量空间
2. 向量的标准运算:加法和乘法
3. 什么是范数，如何用它来测量向量
4. 什么是内积以及它是如何形成向量几何的
5. 数学向量如何映射到数值数组
6. 不同的p范数及其用途
7. 矢量表示的重要计算用途
8. 如何用一个平均向量和协方差矩阵来表征向量数据
9. 高维向量空间的性质
10. 矩阵的基本符号
11. 矩阵作为线性映射的观点
12. 如何使用矩阵实现基本几何变换
13. 矩阵乘法的定义及其代数性质
14. 矩阵的基本解剖学
---
## 1.Vector spaces 向量空间
### 1.1 Vector
1. Vectors :  实数的有序元组$$ [𝑥1,𝑥2,…𝑥𝑛],𝑥𝑖∈ℝ$$
2. A vector: dimension n , direction orthogonal 

### 1.2  ℝ𝑛
-   ℝ : 实数集
-   ℝ≥0 ：正数集
-   ℝ𝑛 ：n个实数的元组集合
-   ℝ𝑛×𝑚 ：𝑛×𝑚的矩阵
-   (ℝ𝑛,ℝ𝑛)→ℝ： 一对n维向量到一个实数的映射
### 1.3 Vectors 使用
1. composed: addition
2. compared: norms/ inner product
3. weighted: scaling缩放比例
### 1.4 Operation
#### Addition
$$𝜆1𝐱1+𝜆2𝐱2+⋯+𝜆𝑛𝐱𝐧$$
#### linear interpolate 线性差值
$$\text{lerp}(\vec{x}, \vec{y}, \alpha) = (1-\alpha) \vec{x} + (\alpha) \vec{y}$$
### 1.5 Vector big？
$\bf x$ (written as $||{\bf x}||$) can be computed directly using `np.linalg.norm()`. This is equal to:
$$ \|{\bf x}\|_2 = \sqrt{x_0^2 + x_1^2 + x_2^2 + \dots + x_n^2  } $$
#### norms 范数
𝐿𝑝-norms：$$\|\vec{x}\|_p = \left(\sum_i x_i^p\right)^\frac{1}{p}$$
### 1.6 Unit vectors and normalization
$\frac{1}{||{\bf x}||_2}$.
### 1.7 Inner product
An inner product $(\real^N \times \real^N) \rightarrow \real$ measures the *angle* between two real vectors. It is related to the **cosine distance**:
    
$$
\cos \theta = \frac{ {\bf x} \bullet {\bf y}} {||{\bf x}|| \  ||{\bf y}||}.$$

For **unit vectors**, we can forget about the denominator, since $||{\bf x}||=1, ||{\bf y}||=1$, so $\cos \theta = {\bf x} \bullet {\bf y}$.


The computation of the dot product, for real-valued vectors in $\real^N$, is simply the sum of the element-wise products:

   
$$
\vec{x}\bullet \vec{y} = \sum_i x_i y_i.
$$