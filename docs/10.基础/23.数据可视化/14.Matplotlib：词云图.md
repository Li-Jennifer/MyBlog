## wordcloud
`pip install wordcloud`
```python
from wordcloud import WordCloud

with open("data/a_new_hope.txt", encoding="utf-8") as file:
     # 数据文件
     txt = file.read()
     # 如果数据文件中包含的有中文的话，font_path必须指定字体，否则中文会乱码
     # collocations：是否包括两个词的搭配，默认为True，如果为true的时候会有
     # 重复的数据，这里我不需要重复数据，所以设置为False
     # width 幕布的宽度，height 幕布的高度
     # max_words 要显示的词的最大个数
     # generate 读取文本文件
     wordcloud = WordCloud(font_path="C:/Windows/Fonts/simfang.ttf",
                                             collocations=False,
                       background_color="black",
                       width=800,
                       height=600,
                       max_words=50).generate(txt)
     # 生成图片
     image = wordcloud.to_image()
     # 展示图片
     image.show()
     # 写入文件
     wordcloud.to_file("tag.jpg")

```
![](attachments/截屏2022-08-26%20下午8.31.19.png)
参数：[https://www.yuque.com/richteam/python/pr2zc5](https://www.yuque.com/richteam/python/pr2zc5)
## jieba 分词模块
`pip install jieba`
```python
import jieba

seg_list = jieba.cut("我来到北京清华大学")  # 默认是精确模式
print(" ".join(seg_list))

seg_list = jieba.cut("我来到北京清华大学", cut_all=True)
print("Full Mode: " + " ".join(seg_list))  # 全模式

seg_list = jieba.cut("我来到北京清华大学", cut_all=False)
print("Default Mode: " + "  ".join(seg_list))  # 精确模式

seg_list = jieba.cut("小明硕士毕业于中国科学院计算所，后在日本京都大学深造")  # 默认是精确模式
print(" ".join(seg_list))

seg_list = jieba.cut_for_search("小明硕士毕业于中国科学院计算所，后在日本京都大学深造")  # 搜索引擎模式
print(" ".join(seg_list))
```