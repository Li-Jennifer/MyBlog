---
title: Request
date: 2022-09-08 16:13:23
permalink: /pages/f66659/
categories:
  - 基础
  - 爬虫
tags:
  - 
author: 
  name: Jennifer
  link: https://github.com/Li-Jennifer
---
## 基本使用
官方文档: [http://cn.python‐requests.org/zh_CN/latest/](http://cn.python‐requests.org/zh_CN/latest/)

快速上手: [http://cn.python‐requests.org/zh_CN/latest/user/quickstart.html](http://cn.python‐requests.org/zh_CN/latest/user/quickstart.html)

安装：`pip install requests`

属性：
```python
类型 ：models.Response

r.text : 获取网站源码
r.encoding ：访问或定制编码方式
r.url ：获取请求的url
r.content ：响应的字节类型
r.status_code ：响应的状态码
r.headers ：响应的头信息
```
## get请求
```python
import requests
url = 'https://www.baidu.com/s'
headers = {
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'
}

data = {
'wd':'北京'
}

response = requests.get(url=url,params=data,headers=headers)
content = response.text
print(content)

# 总结：
# （1）参数使用params传递
# （2）参数无需urlencode编码
# （3）不需要请求对象的定制
# （4）请求资源路径中的？可以加也可以不加
```
## post请求
```python
import requests
url = 'https://fanyi.baidu.com/sug'
headers = {
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'
}

data = {
'kw': 'eye'
}
response = requests.post(url=url,data=data,headers=headers)
content =response.text

import json
obj = json.loads(content,encoding='utf-8')
print(obj)

# 总结：
# （1）post请求 是不需要编解码
# （2）post请求的参数是data
# （3）不需要请求对象的定制
```
## 代理
```python
import requests
url = 'http://www.baidu.com/s?'

headers = {
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36',
}

data = {
'wd': 'ip'
}

proxy = {
'http': '212.129.251.55:16816'
}

response = requests.get(url=url, params=data, headers=headers, proxies=proxy)
content = response.text

with open('daili.html', 'w', encoding='utf-8')as fp:
    fp.write(content)
```
## 案例：Cookie 定制 中国古诗词网站
难点:  隐藏域 验证码
```python
import requests

# 这是登陆页面的url地址
url = 'https://so.gushiwen.cn/user/login.aspx？from=http://so.gushiwen.cn/user/collect.aspx'

headers = {
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'
}

# 获取页面的源码
response = requests.get(url = url,headers = headers)
content = response.text

# 解析页面源码 然后获取_VIEWSTATE __VIEWSTATEGENERATOR
from bs4 import BeautifulSoup
soup = BeautifulSoup(content,'lxml')

# 获取_VIEWSTATE
viewstate = soup.select('#__VIEWSTATE')[0].attrs.get('value')
# 获取__VIEWSTATEGENERATOR
viewstategenerator = soup.select('#__VIEWSTATEGENERATOR')[0].attrs.get('value')

# 获取验证码图片
code = soup.select('#imgCode')[0].attrs.get('src')
code_url = 'https://so.gushiwen.cn' + code

#requests里面有一个方法 session（） 通过session的返回值 就能使用请求变成一个对象
session = requests.session()
# 验证码的url的内容
response_code = session.get(code_url)
# 注意此时要使用二进制数据 因为我们要使用的是图片的下载
content_code = response_code.content
# wb的模式就是将二进制数据写入到文件
with open('code.jpg','wb')as fp:
    fp.write(content_code)

# code的参数 就可以登陆
code_name = input('请输入你的验证码')

# 点击登陆
url_post = 'https://so.gushiwen.cn/user/login.aspx?from=http%3a%2f%2fso.gushiwen.cn%2fuser%2fcollect.aspx'
data_post = {
	'__VIEWSTATE': viewstate,
	'__VIEWSTATEGENERATOR': viewstategenerator,
	'from': 'http://so.gushiwen.cn/user/collect.aspx',
	'email': '595165358@qq.com',
	'pwd': 'action',
	'code': code_name,
	'denglu': '登录',
}

response_post = session.post(url = url, headers = headers, data = data_post)
content_post = response_post.text
with open('gushiwen.html','w',encoding= ' utf-8')as fp:
    fp.write(content_post)
```

